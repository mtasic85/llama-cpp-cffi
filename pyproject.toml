[tool.poetry]
name = "llama-cpp-cffi"
version = "0.1.2"
description = "Python binding for llama.cpp using cffi"
homepage = "https://github.com/tangledgroup/llama-cpp-cffi"
repository = "https://github.com/tangledgroup/llama-cpp-cffi"
authors = ["Marko Tasic <mtasic85@gmail.com>", "Tangled Group, Inc <info@tangledgroup.com>"]
license = "MIT"
readme = "README.md"
packages = [{include = "llama"}]
include = [{path = "llama/*.so"}]

[tool.poetry.dependencies]
python = "^3.10"
attrs = "^23.2.0"
huggingface-hub = "^0.24.0"
cffi = "^1.16.0"
setuptools = "^71.0.3"
psutil = "^6.0.0"
transformers = "^4.42.4"
jinja2 = "^3.1.4"
sentencepiece = "^0.2.0"
protobuf = "^5.27.2"
openai = {version = "^1.35.15", optional = true}
aiohttp = {extras = ["speedups"], version = "^3.9.5", optional = true}
uvloop = {version = "^0.19.0", optional = true}

[tool.poetry.extras]
openai = ["openai", "aiohttp"]
uvloop = ["uvloop"]

[tool.poetry.group.dev.dependencies]
cibuildwheel = "^2.19.2"

[tool.poetry.scripts]
build = "scripts.build:build"
clean = "scripts.clean:clean"

[tool.poetry.build]
script = "scripts/build.py"

[tool.cibuildwheel]
build-frontend = "build"
before-build = "pip install poetry"
skip = ["cp36-*", "cp37-*", "cp38-*", "cp39-*", "pp*", "*-win32", "*i686"]
manylinux-x86_64-image = "manylinux_2_28"
manylinux-aarch64-image = "manylinux_2_28"
musllinux-x86_64-image = "musllinux_1_2"
musllinux-aarch64-image = "musllinux_1_2"
build-verbosity=3
repair-wheel-command = ""
environment = {"LD_LIBRARY_PATH" = "/project/cuda-12.5.1/dist/lib64:/project/cuda-12.5.1/dist/targets/x86_64-linux/lib:/project/cuda-12.5.1/dist/lib64/stubs:$LD_LIBRARY_PATH", "CUDA_HOME" = "/project/cuda-12.5.1/dist"}

[tool.cibuildwheel.pyodide]

[build-system]
requires = ["poetry-core", "cffi", "setuptools"]
build-backend = "poetry.core.masonry.api"
